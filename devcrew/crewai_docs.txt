[AGENTE]
What is an Agent?

An agent is an autonomous unit programmed to:

1. Perform tasks
2. Make decisions
3. Communicate with other agents

Think of an agent as a member of a team, with specific skills and a particular job to do. Agents can have different roles like 'Researcher', 'Writer', or 'Customer Support', each contributing to the overall goal of the crew.

[AGENTE] Attributes¶
Attribute	

Role:	Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.
Goal:	The individual objective that the agent aims to achieve. It guides the agent's decision-making process.
Backstory:	Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.
LLM (optional):	Represents the language model that will run the agent. It dynamically fetches the model name from the OPENAI_MODEL_NAME environment variable, defaulting to "gpt-4" if not specified.
Tools (optional):	Set of capabilities or functions that the agent can use to perform tasks. Expected to be instances of custom classes compatible with the agent's execution environment. Tools are initialized with a default value of an empty list.
Function Calling LLM (optional):	Specifies the language model that will handle the tool calling for this agent, overriding the crew function calling LLM if passed. Default is None.
Max Iter (optional):	The maximum number of iterations the agent can perform before being forced to give its best answer. Default is 25.
Max RPM (optional):	The maximum number of requests per minute the agent can perform to avoid rate limits. It's optional and can be left unspecified, with a default value of None.
max_execution_time (optional):	Maximum execution time for an agent to execute a task It's optional and can be left unspecified, with a default value of None, menaning no max execution time
Verbose (optional):	Setting this to True configures the internal logger to provide detailed execution logs, aiding in debugging and monitoring. Default is False.
Allow Delegation (optional):	Agents can delegate tasks or questions to one another, ensuring that each task is handled by the most suitable agent. Default is True.
Step Callback (optional):	A function that is called after each step of the agent. This can be used to log the agent's actions or to perform other operations. It will overwrite the crew step_callback.
Cache (optional):	Indicates if the agent should use a cache for tool usage. Default is True.

Creating an [AGENTE]¶
Agent Interaction

Agents can interact with each other using crewAI's built-in delegation and communication mechanisms. This allows for dynamic task management and problem-solving within the crew.

To create an agent, you would typically initialize an instance of the Agent class with the desired properties. Here's a conceptual example including all attributes:


# Example: Creating an agent with all attributes

in agents.yaml file

process_engineer:
  role: >
    Engenheiro de Processos
  goal: >
    Analisar o input do usuário e determinar a estrutura de projeto mais eficaz
  backstory: >
    Como um planejador de projeto experiente, você tem a habilidade de 
    visualizar a estrutura ideal para qualquer projeto baseado em um simples input. 
    Usando sua experiência e as ferramentas à sua disposição, você define o caminho a seguir, 
    garantindo que o projeto seja realizado da maneira mais eficiente possível.


in crew.py file

from crewai import Agent

@agent
	def process_engineer(self) -> Agent:
		return Agent(
			config=self.agents_config['process_engineer'],
      tools=[my_tool1, my_tool2],  # Optional, defaults to an empty list
      llm=my_llm,  # Optional
      function_calling_llm=my_llm,  # Optional
      max_iter=15,  # Optional
      max_rpm=None, # Optional
      verbose=True,  # Optional
      allow_delegation=True,  # Optional
      step_callback=my_intermediate_step_callback,  # Optional
      cache=True  # Optional
      memory=True # Optional
		)

Conclusion¶
Agents are the building blocks of the CrewAI framework. By understanding how to define and interact with agents, you can create sophisticated AI systems that leverage the power of collaborative intelligence.

[TAREFAS]
Tasks

Overview of a [TAREFAS]¶
What is a Task?

In the crewAI framework, tasks are specific assignments completed by agents. They provide all necessary details for execution, such as a description, the agent responsible, required tools, and more, facilitating a wide range of action complexities.

Tasks within crewAI can be collaborative, requiring multiple agents to work together. This is managed through the task properties and orchestrated by the Crew's process, enhancing teamwork and efficiency.

[TAREFAS] Attributes¶
Attribute	Description
Description:	A clear, concise statement of what the task entails.
Agent:	The [AGENTE] responsible for the task, assigned either directly or by the crew's process.
Expected Output:	A detailed description of what the task's completion looks like.
Tools (optional):	The functions or capabilities the agent can utilize to perform the task.
Async Execution (optional):	If set, the task executes asynchronously, allowing progression without waiting for completion.
Context (optional):	Specifies tasks whose outputs are used as context for this task.
Config (optional):	Additional configuration details for the agent executing the task, allowing further customization.
Output JSON (optional):	Outputs a JSON object, requiring an OpenAI client. Only one output format can be set.
Output Pydantic (optional):	Outputs a Pydantic model object, requiring an OpenAI client. Only one output format can be set.
Output File (optional):	Saves the task output to a file. If used with Output JSON or Output Pydantic, specifies how the output is saved.
Callback (optional):	A Python callable that is executed with the task's output upon completion.
Human Input (optional):	Indicates if the task requires human feedback at the end, useful for tasks needing human oversight.

Creating a [TAREFAS]¶
Creating a task involves defining its scope, responsible agent, and any additional attributes for flexibility:

in task.yaml file

task_name:
  description: >
    Com base na estrutura do projeto e nos prompts otimizados, 
    programar a lógica do projeto, configurando agentes, tarefas e processos para a implementação efetiva.
  expected_output: >
    Um ou mais arquivos de código-fonte contendo a implementação completa do projeto CrewAi, 
    incluindo a configuração dos agentes, definição de tarefas e a lógica de processo, conforme os prompts otimizados.

in crew.py file

from crewai import Task

@task
	def task_name(self) -> Task:
		return Task(
			config=self.tasks_config['task_name'],
			agent=self.agents_name(),
		)

[TAREFAS] Assignment

Directly specify an agent for assignment or let the hierarchical CrewAI's process decide based on roles, availability, etc.

Referring to Other [TAREFAS]¶
In crewAI, the output of one task is automatically relayed into the next one, but you can specifically define what tasks' output, including multiple should be used as context for another task.

This is useful when you have a task that depends on the output of another task that is not performed immediately after it. This is done through the context attribute of the task:


# ...

	@task
	def planning_task(self) -> Task:
		return Task(
			config=self.tasks_config['planning_task'],
			agent=self.process_engineer(),
		)

	@task
	def prompting_task(self) -> Task:
		return Task(
			config=self.tasks_config['prompting_task'],
			agent=self.prompt_engineer(),
		)
  
	@task
	def coding_task(self) -> Task:
		return Task(
			config=self.tasks_config['coding_task'],
			agent=self.developer(),
   		output_file='report.md'
		)

#...
Asynchronous Execution¶
You can define a task to be executed asynchronously. This means that the crew will not wait for it to be completed to continue with the next task. This is useful for tasks that take a long time to be completed, or that are not crucial for the next tasks to be performed.

You can then use the context attribute to define in a future task that it should wait for the output of the asynchronous task to be completed.


#...

@task
	def task_name(self) -> Task:
		return Task(
			config=self.tasks_config['task_name'],
			agent=self.agents_name(),
      async_execution=True # Will be executed asynchronously
		)

@task
	def task_name2(self) -> Task:
		return Task(
			config=self.tasks_config['task_name2'],
			agent=self.agents_name2(),
      async_execution=True # Will be executed asynchronously
		)

@task
	def task_name3(self) -> Task:
		return Task(
			config=self.tasks_config['task_name3'],
			agent=self.agents_name3(),
      context=[task_name, task_name2] # Will wait for the output of the two tasks to be completed
		)


#...
Callback Mechanism¶
The callback function is executed after the task is completed, allowing for actions or notifications to be triggered based on the task's outcome.


# ...

def callback_function(output: TaskOutput):
    # Do something after the task is completed
    # Example: Send an email to the manager
    print(f"""
        Task completed!
        Task: {output.description}
        Output: {output.raw_output}
    """)

@task
	def task_name(self) -> Task:
		return Task(
			config=self.tasks_config['task_name'],
			agent=self.agents_name(),
      callback=callback_function
		)

#...
Accessing a Specific [TAREFAS] Output¶
Once a crew finishes running, you can access the output of a specific task by using the output attribute of the task object:


# ...
@task
	def task_name(self) -> Task:
		return Task(
			config=self.tasks_config['task_name'],
			agent=self.agents_name(),
		)

#...

crew = Crew(
    agents=[research_agent],
    tasks=[task_name, task_name2, task_name3],
    verbose=2
)

result = crew.kickoff()

# Returns a TaskOutput object with the description and results of the task
print(f"""
    Task completed!
    Task: {task1.output.description}
    Output: {task1.output.raw_output}
""")

Tool Override Mechanism¶
Specifying tools in a task allows for dynamic adaptation of agent capabilities, emphasizing CrewAI's flexibility.

Error Handling and Validation Mechanisms¶
While creating and executing tasks, certain validation mechanisms are in place to ensure the robustness and reliability of task attributes. These include but are not limited to:

Ensuring only one output type is set per task to maintain clear output expectations.
Preventing the manual assignment of the id attribute to uphold the integrity of the unique identifier system.
These validations help in maintaining the consistency and reliability of task executions within the crewAI framework.

Conclusion¶
Tasks are the driving force behind the actions of agents in crewAI. By properly defining tasks and their outcomes, you set the stage for your AI agents to work effectively, either independently or as a collaborative unit. Equipping tasks with appropriate tools, understanding the execution process, and following robust validation practices are crucial for maximizing CrewAI's potential, ensuring agents are effectively prepared for their assignments and that tasks are executed as intended.

[CREW]
What is a Crew?¶
A crew in crewAI represents a collaborative group of agents working together to achieve a set of tasks. Each crew defines the strategy for task execution, agent collaboration, and the overall workflow.

[CREW] Attributes¶
Attribute:	Description
Tasks:	A list of tasks assigned to the crew.
Agents:	A list of agents that are part of the crew.
Process (optional):	The process flow (e.g., sequential, hierarchical) the crew follows.
Verbose (optional):	The verbosity level for logging during execution.
Manager LLM (optional):	The language model used by the manager agent in a hierarchical process. Required when using a hierarchical process.
Function Calling LLM (optional):	If passed, the crew will use this LLM to do function calling for tools for all agents in the crew. Each agent can have its own LLM, which overrides the crew's LLM for function calling.
Config (optional):	Optional configuration settings for the crew, in Json or Dict[str, Any] format.
Max RPM (optional):	Maximum requests per minute the crew adheres to during execution.
Language (optional):	Language used for the crew, defaults to English.
Language File (optional):	Path to the language file to be used for the crew.
Memory (optional):	Utilized for storing execution memories (short-term, long-term, entity memory).
Cache (optional):	Specifies whether to use a cache for storing the results of tools' execution.
Embedder (optional):	Configuration for the embedder to be used by the crew. mostly used by memory for now
Full Output (optional):	Whether the crew should return the full output with all tasks outputs or just the final output.
Step Callback (optional):	A function that is called after each step of every agent. This can be used to log the agent's actions or to perform other operations; it won't override the agent-specific step_callback.
Task Callback (optional):	A function that is called after the completion of each task. Useful for monitoring or additional operations post-task execution.
Share Crew (optional):	Whether you want to share the complete crew information and execution with the crewAI team to make the library better, and allow us to train models.
Output Log File (optional):	Whether you want to have a file with the complete crew output and execution. You can set it using True and it will default to the folder you are currently and it will be called logs.txt or passing a string with the full path and name of the file.

[CREW] Max RPM

The max_rpm attribute sets the maximum number of requests per minute the crew can perform to avoid rate limits and will override individual agents' max_rpm settings if you set it.

Creating a [CREW]¶
When assembling a crew, you combine agents with complementary roles and tools, assign tasks, and select a process that dictates their execution order and interaction.

Example: Assembling a [CREW]¶

in crew.py file

from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from crewai_tools import FileReadTool

load_dotenv()

@CrewBase
class DevcrewCrew():
	"""Devcrew crew"""
	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'
 
	def __init__(self): # Definindo LLM 
		self.llm = ChatOpenAI(model_name='gpt-3.5-turbo') # Optional

	# Agentes
	@agent
	def process_engineer(self) -> Agent:
		return Agent(
			config=self.agents_config['process_engineer'],
			tools=[FileReadTool()], # Example of custom tool, loaded on the beginning of file
			verbose=True,
			llm=self.llm,
			allow_delegation=False
		)

	@agent
	def prompt_engineer(self) -> Agent:
		return Agent(
			config=self.agents_config['prompt_engineer'],
			verbose=True,
			llm=self.llm,
			allow_delegation=False
		)
	@agent
	def developer(self) -> Agent:
		return Agent(
			config=self.agents_config['developer'],
			# tools=[MyCustomTool()], # Example of custom tool, loaded on the beginning of file
			verbose=True,
			llm=self.llm,
			allow_delegation=False
		)

	#Tarefas
	@task
	def planning_task(self) -> Task:
		return Task(
			config=self.tasks_config['planning_task'],
			agent=self.process_engineer(),
		)

	@task
	def prompting_task(self) -> Task:
		return Task(
			config=self.tasks_config['prompting_task'],
			agent=self.prompt_engineer(),
		)
  
	@task
	def coding_task(self) -> Task:
		return Task(
			config=self.tasks_config['coding_task'],
			agent=self.developer(),
   			output_file='report.md'
		)

	@crew
	def crew(self) -> Crew:
		"""Creates the Devcrew crew"""
		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=2,
			# process=Process.hierarchical, # In case you wanna use that instead https://docs.crewai.com/how-to/Hierarchical/
		)

Memory Utilization¶
Crews can utilize memory (short-term, long-term, and entity memory) to enhance their execution and learning over time. This feature allows crews to store and recall execution memories, aiding in decision-making and task execution strategies.

Cache Utilization¶
Caches can be employed to store the results of tools' execution, making the process more efficient by reducing the need to re-execute identical tasks.

[CREW] Usage Metrics¶
After the crew execution, you can access the usage_metrics attribute to view the language model (LLM) usage metrics for all tasks executed by the crew. This provides insights into operational efficiency and areas for improvement.


# Access the [CREW] usage metrics
crew = Crew(agents=[agent1, agent2], tasks=[task1, task2])
crew.kickoff()
print(crew.usage_metrics)

[CREW] Execution Process¶
Sequential Process: Tasks are executed one after another, allowing for a linear flow of work.
Hierarchical Process: A manager agent coordinates the crew, delegating tasks and validating outcomes before proceeding. Note: A manager_llm is required for this process and it's essential for validating the process flow.

Kicking Off a [CREW]¶
Once your crew is assembled, initiate the workflow with the kickoff() method. This starts the execution process according to the defined process flow.

# Start the crew's task execution

The [CREW] task execution will occur in the main.py file:

in main.py file

from nameoffolder.crew import NomedacrewCrewCrew

def run():
    # Replace with your inputs, it will automatically interpolate any tasks and agents information
    inputs = {
        'variable name': 'conteúdo da variável',
    }
    NomedacrewCrewCrew().crew().kickoff(inputs=inputs)

Exemple using the past Crew:

#!/usr/bin/env python
from devcrew.crew import DevcrewCrew


def run():
    # Replace with your inputs, it will automatically interpolate any tasks and agents information
    inputs = {
        'project_idea': 'Quero uma Crew que faça planejamento de viagens para mim',
    }
    DevcrewCrew().crew().kickoff(inputs=inputs)

END